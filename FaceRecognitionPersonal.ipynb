{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f72e5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import cv2\n",
    "import os\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9156fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== CONFIG ========\n",
    "face_db_path = \"face_db\"\n",
    "model_name = \"VGG-Face\"\n",
    "threshold = 0.4  # Cosine distance threshold\n",
    "label_font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "last_label = None\n",
    "last_distance = 1.0\n",
    "smoothing_decay = 0.1  # Smoothing factor for flicker reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc06055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading face embeddings from DB...\n",
      "[LOADED] Chetan/0.jpg\n",
      "[LOADED] Chetan/1.jpg\n",
      "[LOADED] Chetan/10.jpg\n",
      "[LOADED] Chetan/11.jpg\n",
      "[LOADED] Chetan/12.jpg\n",
      "[LOADED] Chetan/13.jpg\n",
      "[LOADED] Chetan/14.jpg\n",
      "[LOADED] Chetan/15.jpg\n",
      "[LOADED] Chetan/16.jpg\n",
      "[LOADED] Chetan/17.jpg\n",
      "[LOADED] Chetan/18.jpg\n",
      "[LOADED] Chetan/19.jpg\n",
      "[LOADED] Chetan/2.jpg\n",
      "[LOADED] Chetan/20.jpg\n",
      "[LOADED] Chetan/21.jpg\n",
      "[LOADED] Chetan/22.jpg\n",
      "[LOADED] Chetan/23.jpg\n",
      "[LOADED] Chetan/24.jpg\n",
      "[LOADED] Chetan/25.jpg\n",
      "[LOADED] Chetan/26.jpg\n",
      "[LOADED] Chetan/3.jpg\n",
      "[LOADED] Chetan/4.jpg\n",
      "[LOADED] Chetan/5.jpg\n",
      "[LOADED] Chetan/6.jpg\n",
      "[LOADED] Chetan/7.jpg\n",
      "[LOADED] Chetan/8.jpg\n",
      "[LOADED] Chetan/9.jpg\n",
      "[LOADED] Dev/0.jpg\n",
      "[LOADED] Dev/1.jpg\n",
      "[LOADED] Dev/10.jpg\n",
      "[LOADED] Dev/11.jpg\n",
      "[LOADED] Dev/12.jpg\n",
      "[LOADED] Dev/13.jpg\n",
      "[LOADED] Dev/14.jpg\n",
      "[LOADED] Dev/15.jpg\n",
      "[LOADED] Dev/16.jpg\n",
      "[LOADED] Dev/17.jpg\n",
      "[LOADED] Dev/18.jpg\n",
      "[LOADED] Dev/19.jpg\n",
      "[LOADED] Dev/2.jpg\n",
      "[LOADED] Dev/20.jpg\n",
      "[LOADED] Dev/21.jpg\n",
      "[LOADED] Dev/22.jpg\n",
      "[LOADED] Dev/23.jpg\n",
      "[LOADED] Dev/24.jpg\n",
      "[LOADED] Dev/25.jpg\n",
      "[LOADED] Dev/26.jpg\n",
      "[LOADED] Dev/27.jpg\n",
      "[LOADED] Dev/28.jpg\n",
      "[LOADED] Dev/29.jpg\n",
      "[LOADED] Dev/3.jpg\n",
      "[LOADED] Dev/30.jpg\n",
      "[LOADED] Dev/31.jpg\n",
      "[LOADED] Dev/32.jpg\n",
      "[LOADED] Dev/33.jpg\n",
      "[LOADED] Dev/34.jpg\n",
      "[LOADED] Dev/35.jpg\n",
      "[LOADED] Dev/36.jpg\n",
      "[LOADED] Dev/37.jpg\n",
      "[LOADED] Dev/38.jpg\n",
      "[LOADED] Dev/39.jpg\n",
      "[LOADED] Dev/4.jpg\n",
      "[LOADED] Dev/40.jpg\n",
      "[LOADED] Dev/41.jpg\n",
      "[LOADED] Dev/42.jpg\n",
      "[LOADED] Dev/5.jpg\n",
      "[LOADED] Dev/6.jpg\n",
      "[LOADED] Dev/7.jpg\n",
      "[LOADED] Dev/8.jpg\n",
      "[LOADED] Dev/9.jpg\n"
     ]
    }
   ],
   "source": [
    "# ======== Load face database ========\n",
    "print(\"[INFO] Loading face embeddings from DB...\")\n",
    "database = {}\n",
    "\n",
    "for person_folder in os.listdir(face_db_path):\n",
    "    person_path = os.path.join(face_db_path, person_folder)\n",
    "\n",
    "    if not os.path.isdir(person_path):\n",
    "        continue  # Skip non-folder files like .pkl\n",
    "\n",
    "    for img_file in os.listdir(person_path):\n",
    "        if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            print(f\"[SKIPPED] {img_file} is not an image\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img_path = os.path.join(person_path, img_file)\n",
    "            rep = DeepFace.represent(img_path=img_path, model_name=model_name, enforce_detection=False)[0][\"embedding\"]\n",
    "\n",
    "            if person_folder not in database:\n",
    "                database[person_folder] = []\n",
    "\n",
    "            database[person_folder].append(rep)\n",
    "            print(f\"[LOADED] {person_folder}/{img_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] Skipped {img_file} due to error: {e}\")\n",
    "\n",
    "if not database:\n",
    "    print(\"[FATAL] No valid face data found in face_db.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a66c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting webcam. Press ESC to quit.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "print(\"[INFO] Starting webcam. Press ESC to quit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f337984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        face_objs = DeepFace.extract_faces(frame, enforce_detection=False)\n",
    "        for face in face_objs:\n",
    "            try:\n",
    "                x = face['facial_area']['x']\n",
    "                y = face['facial_area']['y']\n",
    "                w = face['facial_area']['w']\n",
    "                h = face['facial_area']['h']\n",
    "            except Exception as e:\n",
    "                print(f\"[SKIP FACE] Bad bounding box: {e}\")\n",
    "                continue\n",
    "\n",
    "            cropped_face = face[\"face\"]\n",
    "\n",
    "            # Represent the live face\n",
    "            emb = DeepFace.represent(cropped_face, model_name=model_name, enforce_detection=False)[0][\"embedding\"]\n",
    "\n",
    "            best_match = \"Unknown\"\n",
    "            best_dist = 1.0\n",
    "\n",
    "            for name, embeddings in database.items():\n",
    "                for ref_emb in embeddings:\n",
    "                    dist = cosine(emb, ref_emb)\n",
    "                    if dist < threshold and dist < best_dist:\n",
    "                        best_match = f\"Detected: {name}\"\n",
    "                        best_dist = dist\n",
    "\n",
    "\n",
    "            # Flicker smoothing\n",
    "            if best_dist < last_distance:\n",
    "                last_label = best_match\n",
    "                last_distance = best_dist\n",
    "            else:\n",
    "                # Decay (if not improving, slowly go back to Unknown)\n",
    "                last_distance += smoothing_decay\n",
    "                if last_distance > threshold:\n",
    "                    last_label = \"Detecting...\"\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            if last_label==\"Unknown\":\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            cv2.putText(frame, last_label, (x, y-10), label_font, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR]: {e}\")\n",
    "\n",
    "    cv2.imshow(\"Face Recognition - DeepFace\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
